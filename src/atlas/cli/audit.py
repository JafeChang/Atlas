"""
Atlas æ•°æ®å®¡è®¡ CLI å‘½ä»¤

æä¾›æ•°æ®åº“æŸ¥è¯¢ã€æ•°æ®å®¡è®¡ã€ç»Ÿè®¡åˆ†æç­‰åŠŸèƒ½ã€‚
"""

import sqlite3
import json
import click
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.tree import Tree
from rich import box


console = Console()


def get_db_connection(db_path: str = "data/atlas.db"):
    """è·å–æ•°æ®åº“è¿æ¥"""
    if not Path(db_path).exists():
        raise click.ClickException(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
    return sqlite3.connect(db_path)


def format_timestamp(timestamp_str: Optional[str]) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    if not timestamp_str:
        return "N/A"
    try:
        dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return timestamp_str


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f} TB"


@click.group()
def audit():
    """Atlas æ•°æ®å®¡è®¡å‘½ä»¤ç»„"""
    pass


@audit.command()
@click.option('--db-path', default='data/atlas.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
def overview(db_path: str):
    """æ•°æ®åº“æ¦‚è§ˆ"""
    try:
        conn = get_db_connection(db_path)
        cursor = conn.cursor()

        # æ•°æ®åº“æ–‡ä»¶ä¿¡æ¯
        db_file = Path(db_path)
        file_size = db_file.stat().st_size

        console.print(f"[bold blue]ğŸ“Š æ•°æ®åº“æ¦‚è§ˆ[/bold blue]")
        console.print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {db_file.absolute()}")
        console.print(f"ğŸ“ æ–‡ä»¶å¤§å°: {format_size(file_size)}")
        console.print()

        # è¡¨ç»Ÿè®¡
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]

        table_stats = []
        total_records = 0

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
            transient=True
        ) as progress:
            task = progress.add_task("æ­£åœ¨ç»Ÿè®¡è¡¨æ•°æ®...", total=len(tables))

            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                total_records += count

                cursor.execute(f"PRAGMA table_info({table})")
                columns = cursor.fetchall()

                table_stats.append((table, count, len(columns)))
                progress.advance(task)

        # æ˜¾ç¤ºè¡¨ç»Ÿè®¡
        table = Table(title="æ•°æ®è¡¨ç»Ÿè®¡", box=box.ROUNDED)
        table.add_column("è¡¨å", style="cyan")
        table.add_column("è®°å½•æ•°", justify="right", style="green")
        table.add_column("åˆ—æ•°", justify="right", style="blue")
        table.add_column("çŠ¶æ€", justify="center")

        for table_name, count, cols in table_stats:
            if count > 0:
                status = "âœ… æœ‰æ•°æ®"
            else:
                status = "âšª ç©º"
            table.add_row(table_name, f"{count:,}", str(cols), status)

        console.print(table)
        console.print(f"\nğŸ“Š æ€»è®°å½•æ•°: {total_records:,}")
        console.print(f"ğŸ“‹ æ€»è¡¨æ•°: {len(tables)}")

        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")


@audit.command()
@click.option('--db-path', default='data/atlas.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
@click.option('--source', help='æŒ‡å®šæ•°æ®æºåç§°')
@click.option('--status', type=click.Choice(['enabled', 'disabled', 'all']), default='all', help='è¿‡æ»¤çŠ¶æ€')
def sources(db_path: str, source: Optional[str], status: str):
    """æ•°æ®æºå®¡è®¡"""
    try:
        conn = get_db_connection(db_path)
        cursor = conn.cursor()

        where_clause = ""
        params = []

        if source:
            where_clause = "AND name = ?"
            params.append(source)

        if status == 'enabled':
            where_clause += " AND enabled = 1"
        elif status == 'disabled':
            where_clause += " AND enabled = 0"

        cursor.execute(f'''
            SELECT name, description, source_type, url, enabled, collection_interval,
                   created_at, updated_at, last_collected_at, last_success_at,
                   collection_count, success_count, error_count, last_error
            FROM data_sources
            WHERE 1=1 {where_clause}
            ORDER BY created_at
        ''', params)

        sources_data = cursor.fetchall()

        if not sources_data:
            console.print("[yellow]âš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®æº[/yellow]")
            return

        # ç»Ÿè®¡ä¿¡æ¯
        total_sources = len(sources_data)
        enabled_count = len([s for s in sources_data if s[4]])
        total_collections = sum(s[10] for s in sources_data)
        total_successes = sum(s[11] for s in sources_data)
        total_errors = sum(s[12] for s in sources_data)

        # æ˜¾ç¤ºç»Ÿè®¡
        console.print(f"[bold blue]ğŸ“¡ æ•°æ®æºå®¡è®¡æŠ¥å‘Š[/bold blue]")
        console.print(f"ğŸ“Š æ•°æ®æºæ€»æ•°: {total_sources}")
        console.print(f"âœ… å¯ç”¨æ•°é‡: {enabled_count}")
        console.print(f"âŒ ç¦ç”¨æ•°é‡: {total_sources - enabled_count}")
        console.print(f"ğŸ”„ æ€»é‡‡é›†æ¬¡æ•°: {total_collections}")
        console.print(f"âœ… æ€»æˆåŠŸæ¬¡æ•°: {total_successes}")
        console.print(f"âŒ æ€»å¤±è´¥æ¬¡æ•°: {total_errors}")

        if total_collections > 0:
            success_rate = (total_successes / total_collections) * 100
            console.print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")

        console.print()

        # è¯¦ç»†ä¿¡æ¯è¡¨
        table = Table(title="æ•°æ®æºè¯¦æƒ…", box=box.ROUNDED)
        table.add_column("åç§°", style="cyan")
        table.add_column("ç±»å‹", style="green")
        table.add_column("çŠ¶æ€", justify="center")
        table.add_column("é‡‡é›†æ¬¡æ•°", justify="right")
        table.add_column("æˆåŠŸç‡", justify="right")
        table.add_column("æœ€åæˆåŠŸ")
        table.add_column("æœ€åé”™è¯¯", style="red")

        for source_data in sources_data:
            (name, description, source_type, url, enabled, interval, created_at, updated_at,
             last_collected_at, last_success_at, collection_count, success_count,
             error_count, last_error) = source_data

            status = "âœ… å¯ç”¨" if enabled else "âŒ ç¦ç”¨"

            if collection_count > 0:
                success_rate = (success_count / collection_count) * 100
                rate_str = f"{success_rate:.1f}%"
            else:
                rate_str = "N/A"

            last_success = format_timestamp(last_success_at)
            error_summary = (last_error or "")[:30] + "..." if last_error and len(last_error) > 30 else (last_error or "")

            table.add_row(
                name,
                source_type,
                status,
                str(collection_count),
                rate_str,
                last_success,
                error_summary
            )

        console.print(table)

        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")


@audit.command()
@click.option('--db-path', default='data/atlas.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
@click.option('--days', default=7, help='ç»Ÿè®¡å¤©æ•°')
def metrics(db_path: str, days: int):
    """ç³»ç»ŸæŒ‡æ ‡åˆ†æ"""
    try:
        conn = get_db_connection(db_path)
        cursor = conn.cursor()

        # æŸ¥è¯¢æŒ‡å®šå¤©æ•°å†…çš„æŒ‡æ ‡
        since_date = (datetime.now() - timedelta(days=days)).isoformat()

        cursor.execute('''
            SELECT timestamp, total_raw_documents, total_processed_documents,
                   documents_last_24h, total_sources, active_sources, failed_sources,
                   avg_processing_time_ms, avg_collection_time_ms, error_rate_last_24h
            FROM system_metrics
            WHERE timestamp >= ?
            ORDER BY timestamp DESC
        ''', (since_date,))

        metrics_data = cursor.fetchall()

        if not metrics_data:
            console.print(f"[yellow]âš ï¸  æœ€è¿‘ {days} å¤©å†…æ²¡æœ‰ç³»ç»ŸæŒ‡æ ‡æ•°æ®[/yellow]")
            return

        console.print(f"[bold blue]ğŸ“ˆ ç³»ç»ŸæŒ‡æ ‡åˆ†æ (æœ€è¿‘ {days} å¤©)[/bold blue]")
        console.print()

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if metrics_data:
            latest = metrics_data[0]
            _, total_raw, total_processed, docs_24h, total_sources, active, failed, _, _, error_rate = latest

            # æŒ‡æ ‡å¡ç‰‡
            metrics_panel = Panel(
                f"ğŸ“„ åŸå§‹æ–‡æ¡£: {total_raw:,}\n"
                f"ğŸ“‹ å¤„ç†æ–‡æ¡£: {total_processed:,}\n"
                f"ğŸ“Š 24å°æ—¶æ–‡æ¡£: {docs_24h:,}\n"
                f"ğŸ“¡ æ€»æ•°æ®æº: {total_sources}\n"
                f"âœ… æ´»è·ƒæ•°æ®æº: {active}\n"
                f"âŒ å¤±è´¥æ•°æ®æº: {failed}\n"
                f"ğŸ“ˆ 24å°æ—¶é”™è¯¯ç‡: {error_rate:.2f}%",
                title="æœ€æ–°ç³»ç»ŸçŠ¶æ€",
                border_style="blue"
            )
            console.print(metrics_panel)
            console.print()

        # è¶‹åŠ¿è¡¨
        table = Table(title="ç³»ç»ŸæŒ‡æ ‡è¶‹åŠ¿", box=box.ROUNDED)
        table.add_column("æ—¶é—´")
        table.add_column("åŸå§‹æ–‡æ¡£", justify="right")
        table.add_column("å¤„ç†æ–‡æ¡£", justify="right")
        table.add_column("æ´»è·ƒæ•°æ®æº", justify="right")
        table.add_column("24å°æ—¶é”™è¯¯ç‡", justify="right")

        for metric in metrics_data[:10]:  # æ˜¾ç¤ºæœ€è¿‘10æ¡è®°å½•
            (timestamp, total_raw, total_processed, docs_24h, total_sources,
             active, failed, avg_proc_time, avg_coll_time, error_rate) = metric

            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            time_str = dt.strftime("%m-%d %H:%M")

            table.add_row(
                time_str,
                f"{total_raw:,}",
                f"{total_processed:,}",
                str(active),
                f"{error_rate:.1f}%"
            )

        console.print(table)

        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")


@audit.command()
@click.option('--db-path', default='data/atlas.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
@click.option('--limit', default=50, help='æ˜¾ç¤ºè®°å½•æ•°é™åˆ¶')
def documents(db_path: str, limit: int):
    """æ–‡æ¡£å®¡è®¡"""
    try:
        conn = get_db_connection(db_path)
        cursor = conn.cursor()

        # åŸå§‹æ–‡æ¡£ç»Ÿè®¡
        cursor.execute(f'''
            SELECT source_id, COUNT(*) as count, MAX(collected_at) as latest
            FROM raw_documents
            GROUP BY source_id
            ORDER BY count DESC
            LIMIT {limit}
        ''')

        raw_docs = cursor.fetchall()

        # å¤„ç†æ–‡æ¡£ç»Ÿè®¡
        cursor.execute(f'''
            SELECT rd.source_id, COUNT(pd.id) as processed_count,
                   AVG(pd.quality_score) as avg_quality,
                   MAX(pd.processed_at) as latest_processed
            FROM raw_documents rd
            LEFT JOIN processed_documents pd ON rd.id = pd.raw_document_id
            GROUP BY rd.source_id
            ORDER BY processed_count DESC
            LIMIT {limit}
        ''')

        processed_docs = cursor.fetchall()

        console.print("[bold blue]ğŸ“„ æ–‡æ¡£å®¡è®¡æŠ¥å‘Š[/bold blue]")
        console.print()

        # åŸå§‹æ–‡æ¡£è¡¨
        if raw_docs:
            table = Table(title="åŸå§‹æ–‡æ¡£ç»Ÿè®¡", box=box.ROUNDED)
            table.add_column("æ•°æ®æº", style="cyan")
            table.add_column("æ–‡æ¡£æ•°é‡", justify="right")
            table.add_column("æœ€åé‡‡é›†æ—¶é—´")

            for source_id, count, latest in raw_docs:
                table.add_row(
                    source_id,
                    f"{count:,}",
                    format_timestamp(latest)
                )

            console.print(table)

        # å¤„ç†æ–‡æ¡£è¡¨
        if processed_docs:
            console.print()

            table = Table(title="å¤„ç†æ–‡æ¡£ç»Ÿè®¡", box=box.ROUNDED)
            table.add_column("æ•°æ®æº", style="cyan")
            table.add_column("å¤„ç†æ•°é‡", justify="right")
            table.add_column("å¹³å‡è´¨é‡åˆ†", justify="right")
            table.add_column("æœ€åå¤„ç†æ—¶é—´")

            for source_id, count, avg_quality, latest in processed_docs:
                quality_str = f"{avg_quality:.1f}" if avg_quality else "N/A"
                table.add_row(
                    source_id,
                    f"{count:,}",
                    quality_str,
                    format_timestamp(latest)
                )

            console.print(table)

        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")


@audit.command()
@click.option('--db-path', default='data/atlas.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
@click.option('--output', '-o', help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
def export(db_path: str, output: Optional[str]):
    """å¯¼å‡ºå®¡è®¡æ•°æ®"""
    try:
        conn = get_db_connection(db_path)
        cursor = conn.cursor()

        # æ”¶é›†æ‰€æœ‰å®¡è®¡æ•°æ®
        audit_data = {
            "export_time": datetime.now().isoformat(),
            "database_path": db_path,
            "data_sources": [],
            "raw_documents_count": 0,
            "processed_documents_count": 0,
            "collection_tasks_count": 0,
            "system_metrics_count": 0
        }

        # æ•°æ®æºä¿¡æ¯
        cursor.execute('''
            SELECT name, source_type, url, enabled, collection_interval,
                   collection_count, success_count, error_count, last_success_at
            FROM data_sources
            ORDER BY name
        ''')

        for row in cursor.fetchall():
            audit_data["data_sources"].append({
                "name": row[0],
                "type": row[1],
                "url": row[2],
                "enabled": bool(row[3]),
                "interval_seconds": row[4],
                "total_collections": row[5],
                "successful_collections": row[6],
                "failed_collections": row[7],
                "last_success_at": row[8]
            })

        # ç»Ÿè®¡ä¿¡æ¯
        cursor.execute("SELECT COUNT(*) FROM raw_documents")
        audit_data["raw_documents_count"] = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM processed_documents")
        audit_data["processed_documents_count"] = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM collection_tasks")
        audit_data["collection_tasks_count"] = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM system_metrics")
        audit_data["system_metrics_count"] = cursor.fetchone()[0]

        # è¾“å‡ºç»“æœ
        if output:
            with open(output, 'w', encoding='utf-8') as f:
                json.dump(audit_data, f, indent=2, ensure_ascii=False)
            console.print(f"[green]âœ… å®¡è®¡æ•°æ®å·²å¯¼å‡ºåˆ°: {output}[/green]")
        else:
            console.print(json.dumps(audit_data, indent=2, ensure_ascii=False))

        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")


if __name__ == '__main__':
    audit()