# Atlas 技术架构 Q&A 文档

> 基于当前技术架构文档的梳理，需要澄清的关键问题和决策点。

---

## 1. 系统复杂度与简化

### Q1.1: 当前架构是否过度设计？
**问题描述**：
当前架构包含 OpenSearch、pgvector、Prefect、Celery、Redis 等多个组件，对于"日新增文档 < 1K"的场景是否过于复杂？

**具体考量**：
- 初期是否可以用 SQLite + 全文索引替代 PostgreSQL + OpenSearch？
- cron 直接调用脚本函数是否比引入 Prefect/Celery 更简单？
- 对象存储是否在初期可以用 JSON 文件存储替代？

**A**：
- 确实过于复杂了，但是预期未来是长期可维护可拓展的，所以设计的比较复杂。但是在起步阶段，我理解是可以分层使用简单快速的替代方案的。所以我希望你基于目标架构，制定出初期架构以及中间的过渡期架构，可以以每日新增文档数为参考依据来区分。要求是从简单方案到复杂方案可迁移、易迁移，不要出现数据丢失的问题。

### Q1.2: 最小可用版本应该如何定义？
**问题描述**：
MVP 版本应该包含哪些核心组件，哪些可以后续添加？

**A**:
MVP版本只要满足方法论核心即可，具体包含哪些核心组件由你来定，可以使用奥卡姆剃刀。

---

## 2. LLM 使用策略与成本控制

### Q2.1: LLM 具体使用量如何预估？
**问题描述**：
日预算 $10 的限制下，各类任务的具体使用量应该如何分配？

**需要明确**：
- 每类任务（抽取/分类/聚合等）的预估调用次数
- 不同模型的成本占比分配
- 成本超限时的具体降级策略和优先级

**A**:
- 初期文档量小的时候使用本地模型即可，支持排队的机制。如果遇到消息队列阻塞，可以降低上游采集速度。

### Q2.2: 本地模型与云端 API 的切换时机？
**问题描述**：
什么成本阈值下应该考虑部署本地模型？

**A**:
- 目前尚不清楚，大概是初期使用本地模型（这个已经有了），在本地模型处理不过来之后再接入API。

---

## 3. 数据采集策略

### Q3.1: 数据源优先级如何确定？
**问题描述**：
哪些数据源是最高优先级的，采集频率应该如何设置？

**需要明确**：
- 首期重点关注的 3-5 个数据源
- 每个数据源的采集频率和窗口时间
- 如何处理数据源的失效和变化

**A**:
- 采集频率支持动态调整即可，目前没有经验可以参考。初期可以考虑同一信息源（同一域名）每5分钟不超过1次采集。后期支持针对不同数据源设定不同的采集策略。需要在生产过程中落地采集策略报告以帮助后期调整策略（非MVP）。

### Q3.2: 反爬虫和访问限制如何处理？
**问题描述**：
遇到访问限制时的具体处理策略是什么？

**需要明确**：
- 访问频率的具体限制值
- User-Agent 的具体格式
- 是否需要代理池或其他绕过机制

**A**:
- 初期不用考虑，初期是本地服务，不会接受外网请求。这个等运行成熟稳定之后再考虑。

---

## 4. 部署与资源配置

### Q4.1: 本地部署的最小配置要求？
**问题描述**：
文档提到的 16GB 内存、500GB SSD 是否过高？

**需要明确**：
- 最小可用配置（8GB 内存是否足够？）
- 组件的可选性分级（哪些是必须的，哪些是可选的）
- 资源使用的优化建议

**A**:
- 本地资源足够。

### Q4.2: 不同规模下的配置建议？
**问题描述**：
随着数据量增长，配置应该如何演进？

**A**:
- 目前没有经验，待稳定运行后再讨论。
---

## 5. 实施与验证

### Q5.1: 第一个可运行版本的具体步骤？
**问题描述**：
从零开始，如何快速搭建一个可验证的系统？

**需要明确**：
- 具体的安装和配置步骤
- 如何验证每个组件是否正常工作
- 第一个数据源的接入和验证流程

**A**:
- 这个会在后面由我手动调用LLM来决策。

### Q5.2: 系统验证的成功标准是什么？
**问题描述**：
如何判断系统已经可以正常运行？

**A**:
- 可以稳定运行一整天，并且采集到有效信息，初期有效信息由我打标。

---

## 6. 数据治理与质量

### Q6.1: 数据质量的具体标准？
**问题描述**：
"标准化治理"模块的具体规则和标准是什么？

**需要明确**：
- 数据完整性的具体要求
- 字段标准化的具体规则
- 质量评分的计算方法

**A**:
- 尚无经验，后面再说。

### Q6.2: 去重的具体实现策略？
**问题描述**：
如何判断两个文档是否重复？

**需要明确**：
- 具体的去重算法（SHA256/SimHash 的阈值）
- 相似度重复和完全重复的处理区别
- 去重失败的处理机制

**A**:
- 使用LLM。

---

## 7. 错误处理与容错

### Q7.1: 数据源失效的处理策略？
**问题描述**：
当某个数据源无法访问时，系统应该如何响应？

**A**:
- 初期可以落地错误日志。

### Q7.2: LLM API 调用失败的恢复机制？
**问题描述**：
API 调用失败时的重试策略和降级方案是什么？

**A**:
- 初期落地错误日志即可。手动降级。

### Q7.3: 数据损坏的检测与修复？
**问题描述**：
如何发现和修复存储中的损坏数据？

**A**:
- 先不考虑这些。
---

## 8. 技术选型细节

### Q8.1: Python 依赖管理的具体约束？
**问题描述**：
uv 的使用是否有具体的最佳实践和约束？

**A**:
- 你来定。

### Q8.2: 数据库选型的技术细节？
**问题描述**：
PostgreSQL vs SQLite 的具体技术差异和选择依据？

**A**:
- 你自己考虑。

### Q8.3: 任务调度的具体实现？
**问题描述**：
cron 调度的配置文件格式和管理方式？

**A**:
- 我也不知道，你来定吧。

---

## 9. 性能与扩展性

### Q9.1: 性能瓶颈的预期位置？
**问题描述**：
在当前架构下，最可能的性能瓶颈是什么？

### Q9.2: 扩展性设计的具体考虑？
**问题描述**：
"新增行业不等于重构系统"的具体实现策略是什么？

---

## 10. 运维与维护

### Q10.1: 日常维护的具体任务清单？
**问题描述**：
系统运行后，需要定期执行的维护任务有哪些？

### Q10.2: 监控告警的具体阈值？
**问题描述**：
各项监控指标的具体告警阈值应该如何设定？

---

## 11. 合规与安全细节

### Q11.1: robots.txt 的具体遵守策略？
**问题描述**：
如何处理 robots.txt 与实际需求的冲突？

**A**:
- 遇到了再说

### Q11.2: 数据保留的具体策略？
**问题描述**：
不同类型数据的具体保留周期是什么？

**A**:
- 初期全部保留，后面量大了再搞策略。

---

## 12. 项目管理

### Q12.1: 第一个里程碑的具体目标？
**问题描述**：
MVP 版本应该实现哪些具体功能和指标？

### Q12.2: 技术债务的管理策略？
**问题描述**：
如何平衡快速实现和代码质量？

---

## 回答格式建议

对于每个问题，请提供：

1. **直接答案**：明确的选择或决策
2. **理由说明**：为什么这样选择
3. **具体参数**：如果适用，提供具体的数值或配置
4. **替代方案**：如果有其他可行的方案
5. **实施建议**：如何在代码中体现这个决策

---

**优先级标注**：
- 🔴 高优先级：影响系统可行性或成本控制
- 🟡 中优先级：影响开发效率或系统性能
- 🟢 低优先级：可以后续优化的问题